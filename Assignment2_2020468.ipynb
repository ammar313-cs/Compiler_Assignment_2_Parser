{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "a1X8qbZdmPax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "\n",
        "TOKEN_TYPES = {\n",
        "    'INTEGER_LITERAL': r'\\d+',\n",
        "    'BOOLEAN_LITERAL': r'true|false',\n",
        "    'IDENTIFIER': r'[a-zA-Z][a-zA-Z0-9]*',\n",
        "    'OPERATOR': r'\\+|\\-|\\*|\\/|\\=|\\=\\=|\\!\\=',\n",
        "    'KEYWORD': r'if|else|print',\n",
        "    'COMMENT': r'\\/\\/.*',\n",
        "    'WHITESPACE': r'\\s+',\n",
        "}\n",
        "\n",
        "class Scanner:\n",
        "    def __init__(self, filename):\n",
        "        self.filename = filename\n",
        "        self.tokens = []\n",
        "        self.keywords = ['if', 'else', 'print']\n",
        "        self.operators = ['+', '-', '*', '/', '=', '==', '!=']\n",
        "        self.current_line = 1\n",
        "\n",
        "    def scan(self):\n",
        "        with open(self.filename, 'r') as file:\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "                while line:\n",
        "                    found_token = False\n",
        "                    for token_type, pattern in TOKEN_TYPES.items():\n",
        "                        match = re.match(pattern, line)\n",
        "                        if match:\n",
        "                            lexeme = match.group(0)\n",
        "                            if token_type != 'WHITESPACE':\n",
        "                                self.tokens.append((token_type, lexeme, self.current_line))\n",
        "                            line = line[match.end():].lstrip()\n",
        "                            found_token = True\n",
        "                            break\n",
        "\n",
        "                    if not found_token:\n",
        "                        print(f\"Lexical error in line {self.current_line}: Invalid token\")\n",
        "                        return\n",
        "\n",
        "                    if token_type == 'COMMENT':\n",
        "                        break\n",
        "                self.current_line += 1\n",
        "\n",
        "    def display_tokens(self):\n",
        "        for token in self.tokens:\n",
        "            print(token)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    filename = input(\"Enter the filename to scan: \")\n",
        "    scanner = Scanner(filename)\n",
        "    scanner.scan()\n",
        "    scanner.display_tokens()\n"
      ],
      "metadata": {
        "id": "R1BuWzjzsvJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Parser:\n",
        "    def __init__(self, tokens):\n",
        "        self.tokens = tokens\n",
        "        self.current_token_index = 0\n",
        "\n",
        "    def parse(self):\n",
        "        try:\n",
        "            while self.current_token_index < len(self.tokens):\n",
        "                self.parse_statement()\n",
        "        except IndexError:\n",
        "            print(\"Syntax error: Incomplete statement\")\n",
        "\n",
        "    def match(self, token_type):\n",
        "        if self.current_token_index < len(self.tokens):\n",
        "            if self.tokens[self.current_token_index][0] == token_type:\n",
        "                self.current_token_index += 1\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def parse_expression(self):\n",
        "\n",
        "        pass\n",
        "\n",
        "    def parse_statement(self):\n",
        "        if self.match('KEYWORD'):\n",
        "            if self.tokens[self.current_token_index - 1][1] == 'if':\n",
        "                self.parse_if_else()\n",
        "            elif self.tokens[self.current_token_index - 1][1] == 'print':\n",
        "                self.parse_print()\n",
        "            else:\n",
        "                print(f\"Syntax error: Invalid keyword\")\n",
        "        elif self.match('IDENTIFIER'):\n",
        "            if self.match('OPERATOR') and self.match('INTEGER_LITERAL'):\n",
        "                pass\n",
        "            else:\n",
        "                print(\"Syntax error: Invalid assignment statement\")\n",
        "        else:\n",
        "            print(\"Syntax error: Invalid statement\")\n",
        "\n",
        "    def parse_if_else(self):\n",
        "        if self.match('BOOLEAN_LITERAL'):\n",
        "\n",
        "            if self.match('KEYWORD') and self.tokens[self.current_token_index - 1][1] == 'print':\n",
        "                self.parse_print()\n",
        "            elif self.match('KEYWORD') and self.tokens[self.current_token_index - 1][1] == 'else':\n",
        "                self.parse_statement()\n",
        "            else:\n",
        "                print(\"Syntax error: Invalid if-else statement\")\n",
        "        else:\n",
        "            print(\"Syntax error: Invalid condition for if-else\")\n",
        "\n",
        "    def parse_print(self):\n",
        "        if self.match('IDENTIFIER'):\n",
        "            pass\n",
        "        else:\n",
        "            print(\"Syntax error: Invalid print statement\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    TOKEN_TYPES = {\n",
        "        'INTEGER_LITERAL': r'\\d+',\n",
        "        'BOOLEAN_LITERAL': r'true|false',\n",
        "        'IDENTIFIER': r'[a-zA-Z][a-zA-Z0-9]*',\n",
        "        'OPERATOR': r'\\+|\\-|\\*|\\/|\\=|\\=\\=|\\!\\=',\n",
        "        'KEYWORD': r'if|else|print',\n",
        "        'COMMENT': r'\\/\\/.*',\n",
        "        'WHITESPACE': r'\\s+',\n",
        "    }\n",
        "\n",
        "    filename = input(\"Enter the filename to scan: \")\n",
        "    scanner = Scanner(filename)\n",
        "    scanner.scan()\n",
        "\n",
        "    parser = Parser(scanner.tokens)\n",
        "    parser.parse()\n",
        "\n"
      ],
      "metadata": {
        "id": "sm7t30Tds3Te"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApzDgMBHs3a0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}